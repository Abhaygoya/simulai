{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Copyright IBM Corp. 2019, 2020, 2021, 2022.\n",
    "\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "\n",
    "#           http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#     Unless required by applicable law or agreed to in writing, software\n",
    "#     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#     See the License for the specific language governing permissions and\n",
    "#     limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/jlsa93/opensource/simulai/simulai/regression/_opinf.py:33: UserWarning: Trying to import MPI in /u/jlsa93/opensource/simulai/simulai/regression/_opinf.py.\n",
      "  warnings.warn(f\"Trying to import MPI in {__file__}.\")\n",
      "/u/jlsa93/opensource/simulai/simulai/regression/_opinf.py:34: UserWarning: mpi4py is not installed. If you want to execute MPI jobs, we recommend you install it.\n",
      "  warnings.warn(\n",
      "/u/jlsa93/opensource/simulai/simulai/parallel.py:24: UserWarning: Trying to import MPI in /u/jlsa93/opensource/simulai/simulai/parallel.py.\n",
      "  warnings.warn(f\"Trying to import MPI in {__file__}.\")\n",
      "/u/jlsa93/opensource/simulai/simulai/parallel.py:25: UserWarning: mpi4py is not installed. If you want to execute MPI jobs, we recommend you install it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from simulai.file import SPFile\n",
    "from simulai.optimization import Optimizer\n",
    "from simulai.residuals import SymbolicOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 1_000\n",
    "N = int(5e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_test = np.array([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_intv = [0, 1]\n",
    "s_intv = np.stack([[-3, -3], [3, 3]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The system of ODEs we aim at solving.\n",
    "#### Damped Gravitational Pendulum:\n",
    "$$\n",
    "    \\frac{d\\,s_1}{d\\,t} = s_2\\\\\n",
    "    \\frac{d\\,s_2}{d\\,t} = \\frac{-b\\,s_2}{m} - \\frac{g\\,sin(s_1)}{L}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_s1 = \"D(s1, t) - s2\"\n",
    "f_s2 = \"D(s2, t) + b*s2/m + g*sin(s1)/L\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_t = np.random.uniform(low=t_intv[0], high=t_intv[1], size=Q)\n",
    "U_s = np.random.uniform(low=s_intv[0], high=s_intv[1], size=(N, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"initial_states.npy\", U_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_input_train = np.tile(U_s[:, None, :], (1, Q, 1)).reshape(N * Q, -1)\n",
    "trunk_input_train = np.tile(U_t[:, None], (N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_input_test = np.tile(initial_state_test[None, :], (Q, 1))\n",
    "trunk_input_test = np.sort(U_t[:, None], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = U_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_labels = [\"t\"]\n",
    "output_labels = [\"s1\", \"s2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(input_labels)\n",
    "n_outputs = len(output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1 = 0.0  # Penalty for the L¹ regularization (Lasso)\n",
    "lambda_2 = 0.0  # Penalty factor for the L² regularization\n",
    "n_epochs = 300_000  # Maximum number of iterations for ADAM\n",
    "lr = 1e-3  # Initial learning rate for the ADAM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    from simulai.models import ImprovedDeepONet\n",
    "    from simulai.regression import SLFNN, ConvexDenseNetwork\n",
    "\n",
    "    n_latent = 100\n",
    "    n_inputs_b = 2\n",
    "    n_inputs_t = 1\n",
    "    n_outputs = 2\n",
    "\n",
    "    # Configuration for the fully-connected trunk network\n",
    "    trunk_config = {\n",
    "        \"layers_units\": 7 * [100],  # Hidden layers\n",
    "        \"activations\": \"tanh\",\n",
    "        \"input_size\": n_inputs_t,\n",
    "        \"output_size\": n_latent * n_outputs,\n",
    "        \"name\": \"trunk_net\",\n",
    "    }\n",
    "\n",
    "    # Configuration for the fully-connected branch network\n",
    "    branch_config = {\n",
    "        \"layers_units\": 7 * [100],  # Hidden layers\n",
    "        \"activations\": \"tanh\",\n",
    "        \"input_size\": n_inputs_b,\n",
    "        \"output_size\": n_latent * n_outputs,\n",
    "        \"name\": \"branch_net\",\n",
    "    }\n",
    "\n",
    "    # Instantiating and training the surrogate model\n",
    "    trunk_net = ConvexDenseNetwork(**trunk_config)\n",
    "    branch_net = ConvexDenseNetwork(**branch_config)\n",
    "\n",
    "    encoder_trunk = SLFNN(input_size=n_inputs_t, output_size=100, activation=\"tanh\")\n",
    "    encoder_branch = SLFNN(input_size=n_inputs_b, output_size=100, activation=\"tanh\")\n",
    "\n",
    "    # It prints a summary of the network features\n",
    "    trunk_net.summary()\n",
    "    branch_net.summary()\n",
    "\n",
    "    pendulum_net = ImprovedDeepONet(\n",
    "        trunk_network=trunk_net,\n",
    "        branch_network=branch_net,\n",
    "        encoder_trunk=encoder_trunk,\n",
    "        encoder_branch=encoder_branch,\n",
    "        var_dim=n_outputs,\n",
    "        devices=\"gpu\",\n",
    "        model_id=\"pendulum_net\",\n",
    "    )\n",
    "\n",
    "    return pendulum_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the network properties:\n",
      "Linear operations layers:\n",
      "\n",
      "[ Linear(in_features=1, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=200, bias=True)]\n",
      "\n",
      "\n",
      "Activations layers:\n",
      "\n",
      "['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'identity']\n",
      "\n",
      "\n",
      "Initializations at each layer:\n",
      "\n",
      "['xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier']\n",
      "Summary of the network properties:\n",
      "Linear operations layers:\n",
      "\n",
      "[ Linear(in_features=2, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=100, bias=True),\n",
      "  Linear(in_features=100, out_features=200, bias=True)]\n",
      "\n",
      "\n",
      "Activations layers:\n",
      "\n",
      "['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'identity']\n",
      "\n",
      "\n",
      "Initializations at each layer:\n",
      "\n",
      "['xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier', 'xavier']\n"
     ]
    }
   ],
   "source": [
    "pendulum_net = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "residual = SymbolicOperator(\n",
    "    expressions=[f_s1, f_s2],\n",
    "    input_vars=input_labels,\n",
    "    output_vars=output_labels,\n",
    "    function=pendulum_net,\n",
    "    inputs_key=\"input_trunk\",\n",
    "    constants={\"b\": 0.05, \"g\": 9.81, \"L\": 1, \"m\": 1},\n",
    "    device=\"gpu\",\n",
    "    engine=\"torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = [1, 1]\n",
    "batch_size = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_config = {\"lr\": lr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\"input_branch\": branch_input_train, \"input_trunk\": trunk_input_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer adam found in torch.optim.\n"
     ]
    }
   ],
   "source": [
    "optimizer = Optimizer(\n",
    "    \"adam\",\n",
    "    params=optimizer_config,\n",
    "    lr_decay_scheduler_params={\n",
    "        \"name\": \"ExponentialLR\",\n",
    "        \"gamma\": 0.9,\n",
    "        \"decay_frequency\": 5_000,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lambda_1\": lambda_1,\n",
    "    \"lambda_2\": lambda_2,\n",
    "    \"residual\": residual,\n",
    "    \"initial_input\": {\"input_trunk\": np.zeros((N, 1)), \"input_branch\": initial_states},\n",
    "    \"initial_state\": initial_states,\n",
    "    \"weights_residual\": [1, 1],\n",
    "    \"weights\": penalties,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n",
      "Using LR decay <class 'torch.optim.lr_scheduler.ExponentialLR'>.\n",
      "Data transferred to GPU.\n",
      "Executing batchwise optimization loop.\n",
      "pde: 1.464051274524536e-05, init: 1.4289336149886367e-06, bound: 0.0 , causality_weights: (1e-25, 0))"
     ]
    }
   ],
   "source": [
    "optimizer.fit(\n",
    "    op=pendulum_net,\n",
    "    input_data=input_data,\n",
    "    n_epochs=n_epochs,\n",
    "    loss=\"opirmse\",\n",
    "    params=params,\n",
    "    device=\"gpu\",\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving model.\")\n",
    "saver = SPFile(compact=False)\n",
    "saver.write(\n",
    "    save_dir=save_path, name=\"pendulum_deeponet\", model=pendulum_net, template=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pendulum numerical solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pendulum:\n",
    "    def __init__(self, rho: float = None, b: float = None, m: float = None) -> None:\n",
    "        self.rho = rho\n",
    "        self.b = b\n",
    "        self.m = m\n",
    "\n",
    "    def eval(self, state: np.ndarray = None, t: float = None) -> np.ndarray:\n",
    "        x = state[0]\n",
    "        y = state[1]\n",
    "\n",
    "        x_residual = y\n",
    "        y_residual = -self.b * y / self.m - self.rho * np.sin(x)\n",
    "\n",
    "        return np.array([x_residual, y_residual])\n",
    "\n",
    "    def run(self, initial_state, t):\n",
    "        solution = odeint(self.eval, initial_state, t)\n",
    "\n",
    "        return np.vstack(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 1000\n",
    "N = int(100)\n",
    "dt = 1 / Q\n",
    "\n",
    "t = np.arange(0, 100, dt)\n",
    "\n",
    "initial_state_0 = np.array([1, 1])\n",
    "\n",
    "s_intv = np.stack([[-2, -2], [2, 2]], axis=0)\n",
    "U_s = np.random.uniform(low=s_intv[0], high=s_intv[1], size=(N, 2))\n",
    "U_s = np.vstack([U_s, np.array([[1, 1]])])\n",
    "\n",
    "solver = Pendulum(rho=9.81, m=1, b=0.05)\n",
    "\n",
    "saver = SPFile(compact=False)\n",
    "pendulum_net = saver.read(model_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(N + 1):\n",
    "    \n",
    "    exact_data = solver.run(U_s[j], t)\n",
    "\n",
    "    initial_state_test = U_s[j]\n",
    "\n",
    "    n_outputs = 2\n",
    "    n_times = 100\n",
    "\n",
    "    branch_input_test = np.tile(initial_state_test[None, :], (Q, 1))\n",
    "    trunk_input_test = np.linspace(0, 1, Q)[:, None]\n",
    "\n",
    "    approximated_data = rober_net.eval(\n",
    "        trunk_data=trunk_input_test, branch_data=branch_input_test\n",
    "    )\n",
    "    data_ = torch.from_numpy(branch_input_test.astype(\"float32\")).to(\"cuda\")\n",
    "    # print(rober_net.branch_network.gate(input_data=data_).cpu().detach().numpy())\n",
    "\n",
    "    eval_list = list()\n",
    "\n",
    "    for i in range(0, n_times):\n",
    "        branch_input_test = np.tile(initial_state_test[None, :], (Q, 1))\n",
    "\n",
    "        approximated_data = rober_net.eval(\n",
    "            trunk_data=trunk_input_test, branch_data=branch_input_test\n",
    "        )\n",
    "        initial_state_test = approximated_data[-1]\n",
    "\n",
    "        eval_list.append(approximated_data)\n",
    "\n",
    "    evaluation = np.vstack(eval_list)\n",
    "    time = np.linspace(0, n_times, evaluation.shape[0])\n",
    "\n",
    "    l2_norm = L2Norm()\n",
    "\n",
    "    error_s1 = 100 * l2_norm(\n",
    "        data=evaluation[:, 0], reference_data=exact_data[:, 0], relative_norm=True\n",
    "    )\n",
    "    error_s2 = 100 * l2_norm(\n",
    "        data=evaluation[:, 1], reference_data=exact_data[:, 1], relative_norm=True\n",
    "    )\n",
    "\n",
    "    print(f\"State {j}, {U_s[j]}.\")\n",
    "    print(f\"Approximation errors, s1: {error_s1} %, s2: {error_s2} \")\n",
    "\n",
    "    if j % 1 == 0:\n",
    "        plt.plot(time, evaluation[:, 0], label=\"Approximated\")\n",
    "        plt.plot(time, exact_data[:, 0], label=\"Exact\", ls=\"--\")\n",
    "        plt.xlabel(\"t (s)\")\n",
    "        plt.ylabel(\"Angle\")\n",
    "\n",
    "        plt.xticks(np.arange(0, 100, 20))\n",
    "        plt.legend()\n",
    "        plt.ylim(1.5 * exact_data[:, 0].min(), 1.5 * exact_data[:, 0].max())\n",
    "        plt.savefig(f\"{model_name}_s1_time_int_{j}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(time, evaluation[:, 1], label=\"Approximated\")\n",
    "        plt.plot(time, exact_data[:, 1], label=\"Exact\", ls=\"--\")\n",
    "        plt.xlabel(\"t (s)\")\n",
    "        plt.ylabel(\"Angular Speed\")\n",
    "\n",
    "        plt.xticks(np.arange(0, 100, 20))\n",
    "        plt.legend()\n",
    "        plt.ylim(1.5 * exact_data[:, 1].min(), 1.5 * exact_data[:, 1].max())\n",
    "        plt.savefig(f\"{model_name}_s2_time_int_{j}.png\")\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
