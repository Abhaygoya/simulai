{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# (C) Copyright IBM Corp. 2019, 2020, 2021, 2022.\n",
                "\n",
                "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "#    you may not use this file except in compliance with the License.\n",
                "#    You may obtain a copy of the License at\n",
                "\n",
                "#           http://www.apache.org/licenses/LICENSE-2.0\n",
                "\n",
                "#     Unless required by applicable law or agreed to in writing, software\n",
                "#     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "#     See the License for the specific language governing permissions and\n",
                "#     limitations under the License.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "612e3def-2995-4d74-abee-d29ecb60a97e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "from scipy.integrate import odeint\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "os.environ[\"engine\"] = \"pytorch\"\n",
                "\n",
                "from simulai.regression import DenseNetwork\n",
                "from simulai.models import DeepONet\n",
                "from simulai.optimization import Optimizer\n",
                "from simulai.metrics import L2Norm\n",
                "from simulai.io import IntersectingBatches"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25a04f22-9c3e-4f15-9f76-b04cfbd51169",
            "metadata": {},
            "outputs": [],
            "source": [
                "def project_to_interval(interval, data):\n",
                "\n",
                "    return interval[1]*(data - data.min())/(data.max() - data.min()) + interval[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "87ef6b8d-a1eb-4e3f-bf64-61485735b1b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "class LotkaVolterra:\n",
                "    \n",
                "    def __init__(self, alpha=None, beta=None, gamma=None, delta=None):\n",
                "        \n",
                "        self.alpha = alpha\n",
                "        self.beta = beta\n",
                "        self.gamma = gamma\n",
                "        self.delta = delta\n",
                "      \n",
                "    def eval(self, state:np.ndarray=None, t:float=None) -> np.ndarray:\n",
                "        \n",
                "        x = state[0]\n",
                "        y = state[1]\n",
                "        \n",
                "        x_residual = self.alpha*x - self.beta*x*y\n",
                "        y_residual = self.delta*x*y - self.gamma*y \n",
                "        \n",
                "        return np.array([x_residual, y_residual])\n",
                "    \n",
                "    def run(self, initial_state, t):\n",
                "            \n",
                "        solution = odeint(self.eval, initial_state, t)\n",
                "\n",
                "        return np.vstack(solution)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59665d76-c916-4db9-9791-2d54e4f2dbf4",
            "metadata": {},
            "outputs": [],
            "source": [
                "alpha = 1.1\n",
                "beta = 0.4\n",
                "gamma = 0.4\n",
                "delta = 0.1\n",
                "dt = 0.01\n",
                "T_max = 150\n",
                "n_samples = int(T_max/dt)\n",
                "train_fraction = 0.8\n",
                "n_samples_train = int(train_fraction*n_samples)\n",
                "delta_t = 10\n",
                "n_chunk_samples = 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4f66009-ebfb-4d80-863c-5cd30d00642b",
            "metadata": {},
            "outputs": [],
            "source": [
                "t = np.arange(0, T_max, dt)\n",
                "\n",
                "initial_state = np.array([20, 5])\n",
                "\n",
                "solver = LotkaVolterra(alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
                "\n",
                "data = solver.run(initial_state, t)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "88317b21-3e06-46fc-abfb-6c4172dedf3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "batcher = IntersectingBatches(skip_size=1, batch_size=int(delta_t/dt))\n",
                "\n",
                "time_chunks_ = batcher(input_data=t[:n_samples_train])\n",
                "data_chunks = batcher(input_data=data[:n_samples_train])\n",
                "\n",
                "T_max_train = n_samples_train*dt\n",
                "\n",
                "time_aux = [t[(t >= i) & (t <= i + delta_t)] for i in np.arange(T_max_train, T_max, delta_t)]\n",
                "data_aux = [data[(t >= i) & (t <= i + delta_t)] for i in np.arange(T_max_train, T_max, delta_t)]\n",
                "\n",
                "initial_states = [chunk[0] for chunk in data_chunks]\n",
                "\n",
                "time_chunks = [project_to_interval([0, 1], chunk)[:, None] for chunk in time_chunks_]\n",
                "\n",
                "time_chunks_train = list()\n",
                "data_chunks_train = list()\n",
                "\n",
                "for i in range(len(time_chunks)):\n",
                "    \n",
                "    indices = sorted(np.random.choice(time_chunks[i].shape[0], n_chunk_samples))\n",
                "    time_chunks_train.append(time_chunks[i][indices])\n",
                "    data_chunks_train.append(data_chunks[i][indices])\n",
                "\n",
                "initial_states_train = initial_states\n",
                "\n",
                "time_chunks_test = [project_to_interval([0, 1], chunk)[:, None] for chunk in time_aux]\n",
                "data_chunks_test = data_aux\n",
                "initial_states_test = [chunk[0] for chunk in data_aux]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4702db9e-9a59-4284-8010-c91ec1ab6a3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "branch_input_train = np.vstack([np.tile(init[None,:], (time_chunk.shape[0], 1))\n",
                "                                for init, time_chunk in zip(initial_states_train, time_chunks_train)])\n",
                "\n",
                "branch_input_test = np.vstack([np.tile(init, (time_chunk.shape[0], 1))\n",
                "                               for init, time_chunk in zip(initial_states_test, time_chunks_test)])\n",
                "\n",
                "trunk_input_train = np.vstack(time_chunks_train)\n",
                "trunk_input_test = np.vstack(time_chunks_test)\n",
                "\n",
                "output_train = np.vstack(data_chunks_train)\n",
                "output_test = np.vstack(data_chunks_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "782b5693-5dc0-4638-9969-c7e6a18aaffb",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_inputs = 1\n",
                "n_outputs = 2\n",
                "\n",
                "lambda_1 = 0.0  # Penalty for the L\u00b9 regularization (Lasso)\n",
                "lambda_2 = 1e-4  # Penalty factor for the L\u00b2 regularization\n",
                "n_epochs = 2_000  # Maximum number of iterations for ADAM\n",
                "lr = 1e-3  # Initial learning rate for the ADAM algorithm\n",
                "n_latent = 100\n",
                "\n",
                "# Configuration for the fully-connected trunk network\n",
                "trunk_config = {\n",
                "                'layers_units': 3*[100],  # Hidden layers\n",
                "                'activations': 'relu',\n",
                "                'input_size': 1,\n",
                "                'output_size': n_latent*n_outputs,\n",
                "                'name': 'trunk_net'\n",
                "               }\n",
                "\n",
                "# Configuration for the fully-connected branch network\n",
                "branch_config = {\n",
                "                'layers_units': 3*[100],  # Hidden layers\n",
                "                'activations': 'relu',\n",
                "                'input_size': n_outputs,\n",
                "                'output_size': n_latent*n_outputs,\n",
                "                'name': 'branch_net',\n",
                "                }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c4d68d2a-d414-4f5c-930a-745f3af24b73",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instantiating and training the surrogate model\n",
                "trunk_net = DenseNetwork(**trunk_config)\n",
                "branch_net = DenseNetwork(**branch_config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5aa30ca-6f8c-4f0d-9a44-cbb610dbb61e",
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer_config = {'lr': lr}\n",
                "\n",
                "# Maximum derivative magnitudes to be used as loss weights\n",
                "maximum_values = (1/np.linalg.norm(output_train, 2, axis=0)).tolist()\n",
                "\n",
                "params = {'lambda_1': lambda_1, 'lambda_2': lambda_2, 'weights': maximum_values}\n",
                "\n",
                "# It prints a summary of the network features\n",
                "trunk_net.summary()\n",
                "branch_net.summary()\n",
                "\n",
                "input_data = {'input_branch': branch_input_train, 'input_trunk': trunk_input_train}\n",
                "\n",
                "lorenz_net = DeepONet(trunk_network=trunk_net,\n",
                "                      branch_network=branch_net,\n",
                "                      var_dim=n_outputs,\n",
                "                      model_id='lotka_volterra_net')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9fa01a0f-bbac-4655-a30a-9ad016b23505",
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = Optimizer('adam', params=optimizer_config)\n",
                "\n",
                "optimizer.fit(op=lorenz_net, input_data=input_data, target_data=output_train,\n",
                "              n_epochs=n_epochs, loss=\"wrmse\", params=params, device='gpu')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a0e7435-2b2e-44d3-9692-650d192f57a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "approximated_data = lorenz_net.eval(trunk_data=trunk_input_test, branch_data=branch_input_test)\n",
                "\n",
                "l2_norm = L2Norm()\n",
                "\n",
                "error = 100*l2_norm(data=approximated_data, reference_data=output_test, relative_norm=True)\n",
                "\n",
                "for ii in range(n_inputs):\n",
                "\n",
                "    plt.plot(approximated_data[:, ii], label=\"Approximated\")\n",
                "    plt.plot(output_test[:, ii], label=\"Exact\")\n",
                "    plt.legend()\n",
                "    plt.savefig(f'lorenz_deeponet_time_int_{ii}.png')\n",
                "    plt.show()\n",
                "\n",
                "print(f\"Approximation error for the variables: {error} %\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}